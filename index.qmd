---
title: "Self-Conscious Emotions in Sport and Exercise: Relationships of Implicit and Explicit Processes of Authentic and Hubristic Pride and Physical Activity"
shorttitle: "Self-Conscious Emotions in Sport"
author:
  - name: Sascha Leisterer
    corresponding: true
    orcid: 0000-0000-0000-0001
    email: sascha.leisterer@uni-leipzig.de
    affiliations:
      - name: Leipzig University
        department: Department of Sport Science
        address: Jahnallee 59
        city: Leipzig
        region: Saxony
        country: Germany
        postal-code:
author-note:
  status-changes: 
    affiliation-change: ~
    deceased: ~
  disclosures:
    study-registration: ~
    data-sharing: ~
    related-report: ~
    conflict-of-interest: ~
    financial-support: ~
    gratitude: ~
    authorship-agreements: ~
link-citations: true
abstract: "Self-conscious emotions play a crucial role in sports and exercise by reflecting self-related goal achievements. Traditionally, these emotions are explained through explicit attributional processes. However, implicit processes that influence self-related goal orientation are often overlooked. This cross-sectional correlation study reveals that the implicit affiliation motive negatively correlates with authentic pride in ambitious recreational athletes. Additionally, a positive correlation exists between authentic pride and positive affect. No significant relationships were found between these emotions and physical activity. Explicit attribution styles were not associated with either pride or physical activity. Therefore, considering implicit processes in recreational athletes as potential determinants of self-conscious emotions appears to be more significant than previously thought."
keywords: [keyword1, keyword2, keyword3]
bibliography: bibliography.bib
format:
  apaquarto-html: default
  apaquarto-docx: default
 # apaquarto-pdf:
   # documentmode: man
    
comments:
  hypothesis: true
---

```{r setup}
#| include: false

if (!requireNamespace("needs", quietly = TRUE)) {
  install.packages("needs")
}
library(needs)
needs(xfun, tidyverse, remotes, devtools, mice, pastecs,svglite, HLMdiag, gtsummary, cardx, flextable, lme4, nlme, pwr,huxtable, broom.mixed, patchwork, sjPlot, ggcorrplot, lmerTest, MuMIn, mlmhelpr, car)


```

```{r functions}
#| include: false

#### Average two numbers if there is a hyphen####
handle_hyphen <- function(data, column_name) {
  data %>%
    mutate(
      {{column_name}} := ifelse(
        is.na(.[[column_name]]), 
        NA,  # If the value is NA, keep it as NA
        ifelse(
          grepl("-", .[[column_name]]), 
          sapply(strsplit(.[[column_name]], "-"), function(x) mean(as.numeric(x), na.rm = TRUE)), 
          ifelse(
            .[[column_name]] == "", NA,  # Handle empty strings explicitly
            as.character(.[[column_name]])  # Keep the rest as characters
          )
        )
      )
    )
}
#df <- handle_hyphen(df, "WeeklyKM_base") # example use

#### Group similar words in a character variable ####
# Define the function
replace_patterns <- function(data, column_name, patterns) {
  # Dynamically evaluate the column and apply the replacements
  data %>%
    mutate(
      !!column_name := case_when(
        # Loop through the patterns and replacements
        !!!map2(patterns, names(patterns), function(pattern, replacement) {
          # Create case_when conditions: if the pattern matches, replace it
          grepl(pattern, .[[column_name]], ignore.case = TRUE) ~ replacement
        }),
        # Add a fallback to keep original values if no pattern matches
        TRUE ~ .[[column_name]]
      )
    )
}

## Example usage
## Define the patterns and their replacements
#patterns <- c(  "Kraftsport" = "kraft",   "Laufen" = "lauf")

## Apply the function to the 'Sport' column
#df <- replace_patterns(df, "Sport", patterns)

# Now df will have the patterns replaced in the 'Sport' column


#### Create Correlation Table #####
generate_correlation_table <- function(df, display_names) {
  library(Hmisc)
  library(flextable)
  library(officer)
  # Compute correlation matrix
  correlation_matrix <- rcorr(as.matrix(df))
  correlation_matrix_r <- round(correlation_matrix$r, digits = 2)
  
  # Extract lower triangle of the correlation matrix
  lower_triangle <- correlation_matrix_r[lower.tri(correlation_matrix_r)]
  
  # Create a clean correlation matrix
  correlation_matrix_clean <- matrix(NA, nrow = ncol(correlation_matrix_r), ncol = ncol(correlation_matrix_r))
  correlation_matrix_clean[lower.tri(correlation_matrix_clean)] <- lower_triangle
  
  # Compute significance stars
  stars_matrix <- matrix("", nrow = ncol(correlation_matrix_clean), ncol = ncol(correlation_matrix_clean))
  stars_matrix[correlation_matrix$P < 0.01 & correlation_matrix$P > 0] <- "**"
  stars_matrix[correlation_matrix$P >= 0.01 & correlation_matrix$P < 0.05 & correlation_matrix$P > 0] <- "*"
  
  # Append stars to the lower triangle of the correlation matrix
  correlation_matrix_clean[lower.tri(correlation_matrix_clean)] <- paste(correlation_matrix_clean[lower.tri(correlation_matrix_clean)], stars_matrix[lower.tri(stars_matrix)], sep = "")
  # Compute mean and standard deviation of variables
  means <- colMeans(df, na.rm = T) %>% round(2)
  sds <- apply(df, 2, sd, na.rm = T) %>% round(2)# 2 stands for "colums" here
  
  # Create data frame
  correlation_df <- data.frame(Measure = display_names, Mean = means,SD = sds, correlation_matrix_clean)
  
  colnames(correlation_df)[4:ncol(correlation_df)] <- as.character(1:ncol(correlation_matrix_clean))
  
  # Create flextable
  flextable(correlation_df) %>%
    set_header_labels(
      Measure = "Measure", 
      Mean = "Mean", 
      SD = "SD"
    ) %>%
    add_header_row(
      values = c("", "Descriptive Statistics", "Correlations"), 
      colwidths = c(1, 2, ncol(correlation_matrix_clean))
    ) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::autofit() %>%
    flextable::bold(part = "header") %>%
    flextable::font(fontname = "Times New Roman", part = "all") %>%
    flextable::fontsize(size = 12, part = "all") %>%
    flextable::padding(padding.top = 3, padding.bottom = 3, part = "all") %>%
    flextable::border_remove() %>%
    flextable::hline_top(border = fp_border(width = 1.5), part = "header") %>%
    flextable::hline_bottom(border = fp_border(width = 1.5), part = "body") %>%
    flextable::hline(border = fp_border(width = 1), part = "header")
}

## without descriptive statistics next to correlations
generate_correlation_table2 <- function(df, display_names) {
  library(Hmisc)
  library(flextable)
  library(officer)
  
  # Compute correlation matrix and p-values
  corr_result <- rcorr(as.matrix(df))
  r <- round(corr_result$r, 2)
  p <- corr_result$P
  
  # Initialize matrix for formatted output
  formatted_matrix <- matrix("", ncol = ncol(r), nrow = nrow(r))
  
  for (i in 1:nrow(r)) {
    for (j in 1:ncol(r)) {
      if (i > j) {
        stars <- if (is.na(p[i, j])) {
          ""
        } else if (p[i, j] < 0.01) {
          "**"
        } else if (p[i, j] < 0.05) {
          "*"
        } else {
          ""
        }
        formatted_matrix[i, j] <- paste0(r[i, j], stars)
      }
    }
  }
  
  # Turn into a data frame with display names
  formatted_df <- data.frame(Measure = display_names, formatted_matrix, stringsAsFactors = FALSE)
  colnames(formatted_df)[2:ncol(formatted_df)] <- as.character(1:(ncol(formatted_df)-1))
  
  # Create flextable
  flextable(formatted_df) %>%
    set_header_labels(Measure = "Measure") %>%
    add_header_row(values = c("", "Correlations"), colwidths = c(1, ncol(r))) %>%
    flextable::align(align = "center", part = "all") %>%
    flextable::autofit() %>%
    flextable::bold(part = "header") %>%
    flextable::font(fontname = "Times New Roman", part = "all") %>%
    flextable::fontsize(size = 12, part = "all") %>%
    flextable::padding(padding.top = 3, padding.bottom = 3, part = "all") %>%
    flextable::border_remove() %>%
    flextable::hline_top(border = fp_border(width = 1.5), part = "header") %>%
    flextable::hline_bottom(border = fp_border(width = 1.5), part = "body") %>%
    flextable::hline(border = fp_border(width = 1), part = "header")
}


## Example usage
#correlation_names <- c("Age", "Gender","Weekly Kilometers")
#x<-generate_correlation_table(df[,c("Age","Gender","WeeklyKM_base")], correlation_names)
#### Generate mean values for values wit 

# Generate mean values of all variables that have a certain pattern
#df$mean_goals <- rowMeans(df[, grepl("goal", names(df),ignore.case = T)], na.rm = TRUE)
mean_by_pattern<-function(df,searchstring){
  new_var <- rowMeans (df[,grepl(searchstring, names (df), ignore.case = T)], na.rm = T)
  return(new_var)
}
#df$meannew<-mean_by_pattern(df,"goal") #example use

####Descriptives-Funktion: Berechnet Typische deskriptive Werte fÃ¼r alle Variablen eines gegebenen Datensatzes: ######
#Calculate mean, sd, range, min, max of all variables. 
library(dplyr)

mean_sd_median_min_max <- function(df) {
  result <- df %>%
    # Select only numeric columns
    select(where(is.numeric)) %>%
    # Summarise with the desired statistics
    summarise(across(everything(), 
                     list(mean = ~round(mean(., na.rm = TRUE), digits = 2), 
                          sd = ~round(sd(., na.rm = TRUE), digits = 2),
                          median = ~round(median(., na.rm = TRUE), digits = 2),
                          min = ~min(., na.rm = TRUE),
                          max = ~max(., na.rm = TRUE))))
  
  # Create named list
  result_list <- setNames(as.list(result), paste(names(result), sep = ""))
  
  return(result_list)
}

#### Return all variables that are not normally distribute in the dataset####
which_var_not_normal<- function(df) {
  names<-df %>% select(where(is.numeric)) %>% select(where(~ !is.na(var(.)) && var(.) > 0)) %>% stat.desc (basic=F, norm=T) %>% as.data.frame() %>%.["normtest.p",] %>%   .[, . < 0.05 ] %>% names()
  return(names)
}

which_var_not_normal_p<- function(df) {
  names<-df %>% select(where(is.numeric)) %>% select(where(~ !is.na(var(.)) && var(.) > 0)) %>% stat.desc (basic=F, norm=T) %>% as.data.frame() %>%.["normtest.p",] %>%   .[, . < 0.05 ] %>% names()
  not_normal_data<-df[,names]  %>% stat.desc (basic=F, norm=T) %>% as.data.frame() %>%.["normtest.p",]
  return(not_normal_data)
}

##### Show Histograms of all variables #####
print_all_histograms <- function(df, bins_n=20) {
  df_long <- df %>%
    pivot_longer(cols = where(is.numeric), names_to = "variable", values_to = "value") %>% filter(!is.na(value))
  
  plot<- ggplot(df_long, aes(value)) +
    geom_histogram(aes(y = after_stat(density)), colour = "black", fill = "white", bins = bins_n) +
    labs(x = NULL, y = NULL) +
    scale_y_continuous(guide = "none") +
    facet_wrap(~variable, scales = "free") + # Create separate panels for each variable
    stat_function(fun = dnorm,
                  args = list(mean = mean(df_long$value, na.rm = TRUE),
                              sd = sd(df_long$value, na.rm = TRUE)),
                  colour = "black", linewidth = 1)
  
  print (plot)
}


#### Print violin Boxplots####
print_all_violin_boxplots <- function(df, group_col = NULL, dodge_width = 1, facet_nrow = 2, facet_ncol = NULL, point_jitter = 0.1, custom_labels = NULL) {
  # Ensure the required libraries are loaded
  library(ggplot2)
  library(dplyr)
  library(tidyr)
  
  # Convert the data to a long format, keeping only numeric columns
  df_long <- df %>%
    pivot_longer(cols = where(is.numeric), names_to = "variable", values_to = "value") %>%
    filter(!is.na(value))
  
  # Preserve the original order of variables
  variable_order <- colnames(df)[sapply(df, is.numeric)]
  df_long <- df_long %>%
    mutate(variable = factor(variable, levels = variable_order))
  
  # Add group column to the long format if provided
  if (!is.null(group_col)) {
    df_long <- df_long %>%
      mutate(Group = as.factor(df[[group_col]]))
  } else {
    df_long$Group <- "1" # Default group if no grouping is provided
  }
  
  # Create a named vector for custom labels if provided
  if (!is.null(custom_labels)) {
    label_mapping <- custom_labels
  } else {
    label_mapping <- setNames(unique(df_long$variable), unique(df_long$variable)) # Default to current names
  }
  
  # Create the plot
  plot <- ggplot(df_long, aes(x = variable, y = value, fill = Group)) +
    # Violin plot
    geom_violin(aes(fill = Group), linewidth = 1, color = "black", 
                show.legend = FALSE, position = position_dodge(width = dodge_width)) +
    # Boxplot
    geom_boxplot(aes(fill = Group), outlier.size = 2, outlier.shape = 18, outlier.colour = "blue", 
                 width = 0.1, position = position_dodge(width = dodge_width), show.legend = FALSE) +
    # Raw data points with horizontal jitter
    geom_point(position = position_jitter(width = point_jitter, height = 0), 
               size = 1.5, alpha = 0.6, aes(color = Group), show.legend = FALSE) +
    # Summary mean points
    stat_summary(mapping = aes(color = Group), fun = mean, geom = "point", shape = 4, size = 3, 
                 position = position_dodge(width = dodge_width), show.legend = FALSE) +
    # Custom scales
    scale_color_manual(values = c("black", "black")) +
    scale_fill_manual(values = c("1" = "white", "2" = "grey"),
                      labels = c("1" = "Group 1", "2" = "Group 2"),
                      name = "Group") +
    # Theme settings
    theme_classic(base_size = 14, base_family = "sans") +
    theme(axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_blank(),
          axis.ticks.x = element_blank()) +
    # Faceting with custom labels
    facet_wrap(~variable, scales = "free", as.table = TRUE, nrow = facet_nrow, ncol = facet_ncol,
               labeller = labeller(variable = label_mapping))
  
  # Print the plot
  print(plot)
}

##Generate a talbe with descriptives

get_descriptive_table <- function(df, language = "German") {
  library(dplyr)
  library(pastecs)
  
  # Compute statistics
  df_stat <- df %>% 
    stat.desc(basic = FALSE, norm = TRUE) %>% 
    t() %>% 
    as.data.frame() %>% 
    select(-var, -coef.var, -SE.mean, -kurt.2SE, -normtest.W, -skew.2SE)
  
  # Adjust normtest.p formatting
  df_stat <- df_stat %>%
    mutate(
      normtest.p = ifelse(
        normtest.p < 0.001,
        "< .001",
        as.character(round(normtest.p, 3))
      )
    )
  
  # Round all numeric values
  df_stat <- df_stat %>%
    mutate(across(where(is.numeric), ~ round(., 3)))
  
  # Add rownames as a variable
  df_stat <- df_stat %>%
    mutate(Variable = rownames(df_stat)) %>%
    select(Variable, everything())
  
  # Rename columns based on language
  if (language == "German") {
    df_stat <- df_stat %>% 
      rename(
        Median = median,
        Schiefe = skewness,
        Exzess = kurtosis,
        Mittelwert = mean,
        "95% KI" = CI.mean.0.95,
        "SD" = std.dev,
        "p-Wert " = normtest.p
      )
  } else if (language == "English") {
    df_stat <- df_stat %>% 
      rename(
        Median = median,
        Skewness = skewness,
        Kurtosis = kurtosis,
        Mean = mean,
        "95% CI" = CI.mean.0.95,
        "SD" = std.dev,
        "p-Value" = normtest.p
      )
  } else {
    stop("Unsupported language. Please choose either 'German' or 'English'.")
  }
  return(df_stat)}


```

```{r citations}
#| include: false
# 
 if (!requireNamespace("excelbib", quietly = TRUE)) { 
 xfun::install_github("Enno-W/excelbib") 
} 
library(excelbib)

# Create .bib file from the excel list
xlsx_to_bib("https://bit.ly/scemotions-references")
# Add references or cite: https://bit.ly/scemotions_edit_references
```

```{r data import and transformation}
load("PRIMOCA_data_forR_20240203.Rdata")
df<-PRIMOCA_data_forR_20240203

#### Deal with hyphens in weekly_KM_base ####
df <- handle_hyphen(df, "WeeklyKM_base")# See the script "Functions.R" to examine the function
df <- df %>%
  mutate(
    WeeklyH_base = gsub(",", ".", WeeklyH_base)
  )
df <- handle_hyphen(df, "WeeklyH_base") # also a function from the function script, it averages two numbers out if the person wrote something like 40-45

####Dealing with weightlifter or other sport programs #### Hier klÃ¤ren wie genau verfahren werden soll!!

df$SportCode<-df$SportCode %>% dplyr::recode(`3` = 1, `4` = 1)

#### Making everything numeric####
df[] <- sapply(df, as.numeric)

sum(is.na(df))
df[df==-99]<-NA

original_data_amount <-  df %>% select(- "ID", -"Programme" ,-"Age"    ,-   "Gender" ,  -"SportCode", -ends_with("_ave"))%>%  # Select (where colums are numeric)
  summarise(across(everything(), ~ sum(!is.na(.)))) %>% sum() # Apply summary functions to columns to create a new table of summary statistics. Summary functions take vectors as input and return one value, ~sum of values that are not NA. !! The "." is a placeholder for all the things that are passed throught the function !is.na()
original_data_missings_amount <- df %>% select(- "ID", -"Programme" ,-"Age"    ,-   "Gender" ,  -"SportCode", -ends_with("_ave")) %>% summarise(across(everything(), ~ sum(is.na(.)))) %>% sum()
missings_percentage <-round((original_data_missings_amount / original_data_amount) * 100, 0)

####rename the gender ####
df <- df %>%
  mutate(Gender = dplyr::recode(Gender, "1" = "male", "2" = "female", "3" = "diverse"))

### Speed
df$Speed_1<-(df[,"SessionKM_1"]/df[,"SessionH_1"])*60
df$Speed_2<-(df[,"SessionKM_2"]/df[,"SessionH_2"])*60
df$Speed_3<-(df[,"SessionKM_3"]/df[,"SessionH_3"])*60
df$Speed_4<-(df[,"SessionKM_4"]/df[,"SessionH_4"])*60
df$Speed_5<-(df[,"SessionKM_5"]/df[,"SessionH_5"])*60
df$Speed_6<-(df[,"SessionKM_6"]/df[,"SessionH_6"])*60

df$Speed_1_class <- ifelse(df$Speed_1 < 5, "Swimming",
                     ifelse(df$Speed_1 <= 20, "Running", "Cycling"))

df$Speed_2_class <- ifelse(df$Speed_2 < 5, "Swimming",
                     ifelse(df$Speed_2 <= 20, "Running", "Cycling"))

df$Speed_3_class <- ifelse(df$Speed_3 < 5, "Swimming",
                     ifelse(df$Speed_3 <= 20, "Running", "Cycling"))

df$Speed_4_class <- ifelse(df$Speed_4 < 5, "Swimming",
                     ifelse(df$Speed_4 <= 20, "Running", "Cycling"))

df$Speed_5_class <- ifelse(df$Speed_5 < 5, "Swimming",
                     ifelse(df$Speed_5 <= 20, "Running", "Cycling"))

df$Speed_6_class <- ifelse(df$Speed_6 < 5, "Swimming",
                     ifelse(df$Speed_6 <= 20, "Running", "Cycling"))

#### sport specific z-scaling ####

##For baseline (According to sport Code)
df <- df %>%
  group_by(SportCode) %>%
  mutate(WeeklyKM_base = as.numeric(scale(WeeklyKM_base))) %>%
  ungroup()

### For repeated measures ##

# Speed
for (i in 1:6) {
  speed_var <- paste0("Speed_", i)
  class_var <- paste0("Speed_", i, "_class")

  df <- df %>%
    group_by(.data[[class_var]]) %>%
    mutate(!!speed_var := as.numeric(scale(.data[[speed_var]]))) %>%
    ungroup()
}

# KM
for (i in 1:6) {
  km_var <- paste0("SessionKM_", i)
  class_var <- paste0("Speed_", i, "_class")
 
  df <- df %>%
    group_by(.data[[class_var]]) %>%
    mutate(!!km_var := as.numeric(scale(.data[[km_var]]))) %>%
    ungroup()
}

#####Convert Data to long format#####
repeated_measures1<-df %>% ungroup() %>% select( matches("_[1-6]$")) %>% names()# This is a regex, a regular expression to find a certain pattern. The Dollar sign is for "Ends with". Learn more here: https://github.com/ziishaned/learn-regex/blob/master/translations/README-de.md

long_df <- df %>%
  pivot_longer(
    cols = all_of(repeated_measures1), # 
    names_to = c(".value", "Time"),   # Split into a base name and the timepoint
    names_pattern = "(.*)_(\\d+)"     # Regex to split column names like "Goal_1"
  ) %>%
  mutate(
    Time = as.numeric(Time)           # Convert extracted timepoint to numeric
  )

### Dependent variables should lead by one session 
 
 long_df <- long_df %>%
  arrange(ID, Time) %>%
  group_by(ID) %>%
  mutate(
    SessionKM_lead1 = lead(SessionKM, order_by = Time),
    SessionH_lead1 = lead(SessionH, order_by = Time),
    SessionRPE_lead1 = lead(SessionRPE, order_by = Time)
  ) %>%
  ungroup()

#### Centering #####
# Grand mean centering
long_df[, c("Pride_centered", "Dynamics_centered", "PA_gm_centered", "Locus_centered", "Globality_centered", "Affiliation_centered", "Achievement_centered", "Power_centered")] <- scale(long_df[, c("Pride", "Dynamics", "PA", "Locus", "Globality", "Affiliation", "Achievement", "Power")], center = TRUE, scale = FALSE)

# Group mean centering
long_df <- long_df %>%
  group_by(ID) %>%
  mutate(across(c(Pride, PA), 
                ~ . - mean(., na.rm = TRUE), 
                .names = "{.col}_gm_centered")) %>%
  ungroup()

## Rank or Log transformations
long_df$SessionKM_lead1_rank<-rank(long_df$SessionKM_lead1)
long_df$SessionKM_lead1_log <- log(long_df$SessionKM_lead1)
long_df$SessionKM_lead1_log[is.infinite(long_df$SessionKM_lead1_log)] <- 0.000001

long_df$SessionH_lead1_rank <- rank(long_df$SessionH_lead1)
long_df$SessionH_lead1_log <- log(long_df$SessionH_lead1)
long_df$SessionH_lead1_log[is.infinite(long_df$SessionH_lead1_log)] <- 0.000001

long_df$SessionRPE_lead1_rank <- rank(long_df$SessionRPE_lead1)
long_df$SessionRPE_lead1_log <- log(long_df$SessionRPE_lead1)
long_df$SessionRPE_lead1_log[is.infinite(long_df$SessionRPE_lead1_log)] <- 0.000001


long_df$ID<-long_df$ID %>% as.factor()



```

```{r HLM Table for KM}
#| include: false


##### Null model and ICC ####

null_model_km<- lme(SessionKM_lead1 ~ 1, 
                      data=long_df, 
                      random= ~1|ID, 
                      method="ML", 
                      na.action = na.omit) # See the documentation for lme: ?lme --> other options: na.exclude, na.pass...#
summary(null_model_km)
# The "1" stands for the "intercept"
#The formula means: Fixed effects: for "Goal", only the intercepts are estimated. Random effects: "The intercept varies between participants". 
icc_km<-performance::icc(null_model_km)
# 
# model_SessionKM_rank<-lmer(SessionKM_rank~ Pride * Dynamics + Pride * PA + Pride * Locus + Pride * Globality + Pride * Affiliation + 
# Pride * Achievement + Pride * Power + (1 | ID), data = long_df)


model_SessionKM_1 <- lme(
  fixed =   SessionKM_lead1 ~   
   Pride_gm_centered* PA_gm_centered,
  random = ~ 1 | ID,
  data = long_df, 
  na.action=na.omit, 
  
  method = "REML"
)

model_SessionKM_2 <- lme(
  fixed = SessionKM_lead1 ~ 
   Pride_gm_centered* PA_gm_centered+
   Pride_gm_centered* Dynamics_centered + 
   Pride_gm_centered* Locus_centered + 
   Pride_gm_centered* Globality_centered ,
  random = ~ 1 | ID,
  data = long_df, 
  na.action=na.omit, 

  method = "REML"
)

model_SessionKM_3 <- lme(
  fixed = SessionKM_lead1 ~ 
    Pride_gm_centered * PA_gm_centered+ 
    Pride_gm_centered * Dynamics_centered + 
    Pride_gm_centered * Locus_centered + 
    Pride_gm_centered * Globality_centered + 
    Pride_gm_centered * Affiliation_centered + 
    Pride_gm_centered * Achievement_centered + 
    Pride_gm_centered * Power_centered,
  random = ~ 1 | ID,

  data = long_df, 
  na.action=na.omit, 
  method = "REML"
)

model_SessionKM_4 <- lme(
  fixed = SessionKM_lead1 ~ 
   Pride_gm_centered* PA_gm_centered+ 
   Pride_gm_centered* Dynamics_centered +
   Pride_gm_centered* Locus_centered + 
   Pride_gm_centered* Globality_centered + 
   Pride_gm_centered* Affiliation_centered + 
   Pride_gm_centered* Achievement_centered + 
   Pride_gm_centered* Power_centered,
  random = ~ 1 | ID,
  data = long_df, 
  na.action=na.omit,
    method = "REML"
)

### Table Output #####
# Distance
hlmtable<-huxreg("Nullmodell" = null_model_km, 
                 "Model 1" = model_SessionKM_1, 
                 "Model 2" = model_SessionKM_2, 
                 "Model 3" = model_SessionKM_3,
                 statistics = NULL, 
                 number_format = 2, 
                 bold_signif = 0.05, 
                 tidy_args =  list(effects = "fixed"), 
                 error_pos="right",
                coefs = c(
    "(Intercept)" = "(Intercept)",
    "Pride" = "Pride_gm_centered",
     "Positive Affect" = "PA_gm_centered",
    "Dynamics" = "Dynamics_centered",
    "Locus" = "Locus_centered",
    "Globality" = "Globality_centered",
    "Affiliation" = "Affiliation_centered",
    "Achievement" = "Achievement_centered",
    "Power" = "Power_centered",
    "Pride Ã Dynamics" = "Pride_gm_centered:Dynamics_centered",
    "Pride Ã Positive Affect" = "Pride_gm_centered:PA_gm_centered",
    "Pride Ã Locus" = "Pride_gm_centered:Locus_centered",
    "Pride Ã Globality" = "Pride_gm_centered:Globality_centered",
    "Pride Ã Affiliation" = "Pride_gm_centered:Affiliation_centered",
    "Pride Ã Achievement" = "Pride_gm_centered:Achievement_centered",
    "Pride Ã Power" = "Pride_gm_centered:Power_centered")
)

    # weitere Variablen nach Bedarf ergÃ¤nzen
```

```{r SessionKM graphs and assumptions check}
#| include: false
##### Checking Assumptions http://www.regorz-statistik.de/inhalte/r_HLM_2.html ###############################################

# Extract Residuals
SessionKM_residuals <- hlm_resid(model_SessionKM_2, level=1, include.ls = T) 
########Normality Plots #####
# Normality Plot with least square residuals
ndist_plot_km_ls <- ggplot(data = SessionKM_residuals  , aes(.ls.resid)) +
  geom_histogram(aes(y = after_stat(density)), bins=30) +
  stat_function(fun = dnorm,
                args = list(mean = mean(SessionKM_residuals  $.ls.resid),
                            sd = sd(SessionKM_residuals  $.ls.resid)), linewidth=2) # The "groups" (measurement points) are small, thus some are "rank deficient" - the regular residuals provide a less biased estimate

# Normality Plot with residuals
ndist_plot_km<- ggplot(data = SessionKM_residuals, aes(.resid)) +
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30,
                 fill = "gray80",
                 color = "black") +
  stat_function(
    fun = dnorm,
    args = list(
      mean = mean(SessionKM_residuals$.resid),
      sd = sd(SessionKM_residuals$.resid)
    ),
    linewidth = 1,
    color = "black",
    linetype = "dashed"
  ) +
  labs(
    x = "Residuals",
    y = "Density"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )

# QQ line
qqplot_km<-ggplot(SessionKM_residuals, aes(sample = .resid)) +
  stat_qq(shape = 21, color = "black", fill = "gray80", size = 2) +
  stat_qq_line(color = "black", linetype = "dashed") +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )



###### Tests of normality ###############################################

#### Test for the Attribution Model #####
ntest_shapiro_km <-shapiro.test(SessionKM_residuals $.resid)  
ntest_ks_km <-ks.test(SessionKM_residuals  $.resid, "pnorm", mean(SessionKM_residuals  $.resid), sd(SessionKM_residuals  $.resid), exact = T)

######Variance Incluence Factor ####
model_SessionKM_2_lmer <- lmer(
  SessionKM_lead1 ~ 
    Pride_gm_centered * PA_gm_centered +
    Pride_gm_centered * Dynamics_centered + 
    Pride_gm_centered * Locus_centered + 
    Pride_gm_centered * Globality_centered +
    (1 | ID),
  data = long_df,
  na.action = na.omit,
  REML = TRUE
)
vif(model_SessionKM_2_lmer) 


##### Testing for homoscedasticity (homogeneity of variance of residuals), and outliers in the residuals####

resid_plot_km<-ggplot(data = SessionKM_residuals, aes(x = .fitted, y = .resid)) +
  geom_point(shape = 21, color = "black", fill = "gray80", size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = NULL
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )

#resid_plot_km+resid_plot_km_no_logtransform
# Outliers (All)
ggplot(data = SessionKM_residuals , aes(y= .resid)) + theme_gray() + geom_boxplot()

#Outliers per individual
outl_plot_km <- ggplot(SessionKM_residuals, aes(x = .resid, y = ID)) +
  geom_boxplot(outlier.shape = 21, outlier.fill = "gray80", outlier.color = "black", outlier.size = 2) +
  labs(
    y = "Individual No.",
    x = "Residuals"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )


```

```{r HLM Table and graphs for H (Duration)}
#| include: false


##### Null model and ICC ####
null_model_h<- lme(SessionH_lead1_log ~ 1, 
                      data=long_df, 
                      random= ~1|ID, 
                      method="ML", 
                      na.action = na.omit) # See the documentation for lme: ?lme --> other options: na.exclude, na.pass...#
summary(null_model_h)
# The "1" stands for the "intercept"
#The formula means: Fixed effects: for "Goal", only the intercepts are estimated. Random effects: "The intercept varies between participants". 
icc_h<-performance::icc(null_model_h)


model_SessionH_1 <- lme(
  fixed =   SessionH_lead1_log ~   
    Pride_gm_centered* PA_gm_centered,
  random = ~ 1 | ID,
  data = long_df, 
  na.action=na.omit, 
  
  method = "REML"
)

model_SessionH_2 <- lme(
  fixed = SessionH_lead1_log ~ 
        Pride_gm_centered* PA_gm_centered + 
    Pride_gm_centered* Dynamics_centered + 
    Pride_gm_centered* Locus_centered + 
    Pride_gm_centered* Globality_centered ,
  random = ~ 1 | ID,
  data = long_df, 
  na.action=na.omit, 
  
  method = "REML"
)

model_SessionH_3 <- lme(
  fixed = SessionH_lead1_log ~ 
    Pride_gm_centered * PA_gm_centered+ 
    Pride_gm_centered * Dynamics_centered + 
    Pride_gm_centered * Locus_centered + 
    Pride_gm_centered * Globality_centered + 
    Pride_gm_centered * Affiliation_centered + 
    Pride_gm_centered * Achievement_centered + 
    Pride_gm_centered * Power_centered,
  random = ~ 1 | ID,

  data = long_df, 
  na.action=na.omit, 
  
  method = "REML"
)

model_SessionH_4 <- lme(
  fixed = SessionH_lead1 ~ 
   Pride_gm_centered* PA_gm_centered + 
   Pride_gm_centered* Dynamics_centered +
   Pride_gm_centered* Locus_centered + 
   Pride_gm_centered* Globality_centered + 
   Pride_gm_centered* Affiliation_centered + 
   Pride_gm_centered* Achievement_centered + 
   Pride_gm_centered* Power_centered,
  random = ~ 1 | ID,
  data = long_df, 
  na.action=na.omit,
    method = "REML"
)



### Table Output #####
hlmtable_h<-huxreg("Nullmodell" = null_model_h, 
                   "Model 1" = model_SessionH_1, 
                   "Model 2" = model_SessionH_2, 
                   "Model 3" = model_SessionH_3,
                   statistics = NULL, number_format = 2, bold_signif = 0.05, tidy_args =  list(effects = "fixed"), error_pos="right",
                  coefs = c(
    "(Intercept)" = "(Intercept)",
    "Pride" = "Pride_gm_centered",
    "Positive Affect" = "PA_gm_centered",
    "Dynamics" = "Dynamics_centered",
    "Locus" = "Locus_centered",
    "Globality" = "Globality_centered",
    "Affiliation" = "Affiliation_centered",
    "Achievement" = "Achievement_centered",
    "Power" = "Power_centered",
    "Pride Ã Dynamics" = "Pride_gm_centered:Dynamics_centered",
    "Pride Ã Positive Affect" = "Pride_gm_centered:PA_gm_centered",
    "Pride Ã Locus" = "Pride_gm_centered:Locus_centered",
    "Pride Ã Globality" = "Pride_gm_centered:Globality_centered",
    "Pride Ã Affiliation" = "Pride_gm_centered:Affiliation_centered",
    "Pride Ã Achievement" = "Pride_gm_centered:Achievement_centered",
    "Pride Ã Power" = "Pride_gm_centered:Power_centered"
  ))


```

```{r SessionH residual graphs and assumptions check}
#| include: false
##### Checking Assumptions http://www.regorz-statistik.de/inhalte/r_HLM_2.html ###############################################

# Extract Residuals
SessionH_residuals <- hlm_resid(model_SessionH_3, level=1, include.ls = T) 
SessionH_residuals_no_logtransform <- hlm_resid(model_SessionH_4, level=1, include.ls = T) 
########Normality Plots #####
# Normality Plot with least square residuals
ndist_plot_h_ls <- ggplot(data = SessionH_residuals  , aes(.ls.resid)) +
  geom_histogram(aes(y = after_stat(density)), bins=30) +
  stat_function(fun = dnorm,
                args = list(mean = mean(SessionH_residuals  $.ls.resid),
                            sd = sd(SessionH_residuals  $.ls.resid)), linewidth=2) # The "groups" (measurement points) are small, thus some are "rank deficient" - the regular residuals provide a less biased estimate

# Normality Plot with residuals
ndist_plot_h<- ggplot(data = SessionH_residuals, aes(.resid)) +
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30,
                 fill = "gray80",
                 color = "black") +
  stat_function(
    fun = dnorm,
    args = list(
      mean = mean(SessionH_residuals$.resid),
      sd = sd(SessionH_residuals$.resid)
    ),
    linewidth = 1,
    color = "black",
    linetype = "dashed"
  ) +
  labs(
    x = "Residuals",
    y = "Density"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )

#ndist_plot_h+ndist_plot_h_no_logtransform
# QQ line
qqplot_h<-ggplot(SessionH_residuals, aes(sample = .resid)) +
  stat_qq(shape = 21, color = "black", fill = "gray80", size = 2) +
  stat_qq_line(color = "black", linetype = "dashed") +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )
qqplot_h_no_logtransform <-ggplot(SessionH_residuals_no_logtransform, aes(sample = .resid)) +
  stat_qq(shape = 21, color = "black", fill = "black", size = 2) +
  stat_qq_line(color = "black", linetype = "dashed") +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )
# qqplot_h+qqplot_h_no_logtransform


###### Tests of normality ###############################################

#### Test for the Attribution Model #####
ntest_shapiro_h <-shapiro.test(SessionH_residuals $.resid)  
ntest_ks_h <-ks.test(SessionH_residuals  $.resid, "pnorm", mean(SessionH_residuals  $.resid), sd(SessionH_residuals  $.resid), exact = T)
ntest_ks_h_no_logtransform <-ks.test(SessionH_residuals_no_logtransform  $.resid, "pnorm", mean(SessionH_residuals_no_logtransform  $.resid), sd(SessionH_residuals_no_logtransform  $.resid), exact = T)


#### VAriance influence Factor ####
model_SessionH_1_lmer<- lmer(
  SessionH_lead1 ~ Pride_gm_centered * PA_gm_centered + (1 | ID), 
  data = long_df, 
  na.action = na.omit, 
  REML = TRUE
)
vif(model_SessionH_1_lmer)
##### Testing for homoscedasticity (homogeneity of variance of residuals), and outliers in the residuals####

resid_plot_h<-ggplot(data = SessionH_residuals, aes(x = .fitted, y = .resid)) +
  geom_point(shape = 21, color = "black", fill = "gray80", size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = NULL
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )

resid_plot_h_no_logtransform<-ggplot(data = SessionH_residuals_no_logtransform, aes(x = .fitted, y = .resid)) +
  geom_point(shape = 15, color = "black", size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = NULL
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )
#resid_plot_h+resid_plot_h_no_logtransform
# Outliers (All)
ggplot(data = SessionH_residuals , aes(y= .resid)) + theme_gray() + geom_boxplot()

#Outliers per individual
outl_plot_h <- ggplot(SessionH_residuals, aes(x = .resid, y = ID)) +
  geom_boxplot(outlier.shape = 21, outlier.fill = "gray80", outlier.color = "black", outlier.size = 2) +
  labs(
    y = "Individual No.",
    x = "Residuals"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )


```

```{r HLM Table for RPE}
#| include: false


##### Null model and ICC ####

null_model_rpe<- lme(SessionRPE_lead1 ~ 1, 
                      data=long_df, 
                      random= ~1|ID, 
                      method="ML", 
                      na.action = na.omit) # See the documentation for lme: ?lme --> other options: na.exclude, na.pass...#
# The "1" stands for the "intercept"
#The formula means: Fixed effects: for "Goal", only the intercepts are estimated. Random effects: "The intercept varies between participants". 
icc_rpe<-performance::icc(null_model_rpe)
# 
# model_SessionRPE<-lmer(SessionRPE~ Pride * Dynamics + Pride * PA + Pride * Locus + Pride * Globality + Pride * Affiliation + 
# Pride * Achievement + Pride * Power + (1 | ID), data = long_df)


model_SessionRPE_1 <- lme(
  fixed =   SessionRPE_lead1~   
    Pride_gm_centered* PA_gm_centered,
  random = ~ 1 | ID,
  data = long_df, 
  na.action=na.omit, 
  
  method = "REML"
)

model_SessionRPE_2 <- lme(
  fixed = SessionRPE_lead1 ~ 
      Pride_gm_centered * PA_gm_centered+ 
    Pride_gm_centered* Dynamics_centered + 
    Pride_gm_centered* Locus_centered + 
    Pride_gm_centered* Globality_centered ,
  random = ~ 1 | ID,
  data = long_df, 
  na.action=na.omit, 
  
  method = "REML"
)

model_SessionRPE_3 <- lme(
  fixed = SessionRPE_lead1 ~ 
    Pride_gm_centered * PA_gm_centered+ 
    Pride_gm_centered * Dynamics_centered + 
    Pride_gm_centered * Locus_centered + 
    Pride_gm_centered * Globality_centered + 
    Pride_gm_centered * Affiliation_centered + 
    Pride_gm_centered * Achievement_centered + 
    Pride_gm_centered * Power_centered,
  random = ~ 1 | ID,

  data = long_df, 
  na.action=na.omit, 
  
  method = "REML"
)

model_SessionRPE_4 <- lme(
  fixed = SessionRPE_lead1 ~ 
    Pride_gm_centered* PA_gm_centered+ 
    Pride_gm_centered* Dynamics_centered +
    Pride_gm_centered* Locus_centered + 
    Pride_gm_centered* Globality_centered + 
    Pride_gm_centered* Affiliation_centered + 
    Pride_gm_centered* Achievement_centered + 
    Pride_gm_centered* Power_centered,
  random = ~ 1 | ID,
 correlation = nlme::corAR1(form = ~ Time | ID),
  data = long_df, 
  na.action=na.omit,
    method = "REML"
)

### Table Output #####
hlmtable_rpe<-huxreg("Nullmodell" = null_model_rpe, 
                     "Model 1" = model_SessionRPE_1, 
                     "Model 2" = model_SessionRPE_2, 
                     "Model 3" = model_SessionRPE_3,
                     statistics = NULL, number_format = 2, bold_signif = 0.05, tidy_args =  list(effects = "fixed"), error_pos="right",
                     coefs = c(
    "(Intercept)" = "(Intercept)",
    "Pride" = "Pride_gm_centered",
    "Positive Affect" = "PA_gm_centered",
    "Dynamics" = "Dynamics_centered",
    "Locus" = "Locus_centered",
    "Globality" = "Globality_centered",
    "Affiliation" = "Affiliation_centered",
    "Achievement" = "Achievement_centered",
    "Power" = "Power_centered",
    "Pride Ã Dynamics" = "Pride_gm_centered:Dynamics_centered",
    "Pride Ã Positive Affect" = "Pride_gm_centered:PA_gm_centered",
    "Pride Ã Locus" = "Pride_gm_centered:Locus_centered",
    "Pride Ã Globality" = "Pride_gm_centered:Globality_centered",
    "Pride Ã Affiliation" = "Pride_gm_centered:Affiliation_centered",
    "Pride Ã Achievement" = "Pride_gm_centered:Achievement_centered",
    "Pride Ã Power" = "Pride_gm_centered:Power_centered"
  ))
# only use fixed effects in the parentheses



```

```{r SessionHRPE residual graphs and assumptions check}
#| include: false
##### Checking Assumptions http://www.regorz-statistik.de/inhalte/r_HLM_2.html ###############################################

# Extract Residuals
SessionRPE_residuals <- hlm_resid(model_SessionRPE_3, level=1, include.ls = T) 
SessionRPE_residuals_no_logtransform <- hlm_resid(model_SessionRPE_4, level=1, include.ls = T) 
########Normality Plots #####
# Normality Plot with least square residuals
ndist_plot_rpe_ls <- ggplot(data = SessionRPE_residuals  , aes(.ls.resid)) +
  geom_histogram(aes(y = after_stat(density)), bins=30) +
  stat_function(fun = dnorm,
                args = list(mean = mean(SessionRPE_residuals  $.ls.resid),
                            sd = sd(SessionRPE_residuals  $.ls.resid)), linewidth=2) # The "groups" (measurement points) are small, thus some are "rank deficient" - the regular residuals provide a less biased estimate

# Normality Plot with residuals
ndist_plot_rpe<- ggplot(data = SessionRPE_residuals, aes(.resid)) +
  geom_histogram(aes(y = after_stat(density)),
                 bins = 30,
                 fill = "gray80",
                 color = "black") +
  stat_function(
    fun = dnorm,
    args = list(
      mean = mean(SessionRPE_residuals$.resid),
      sd = sd(SessionRPE_residuals$.resid)
    ),
    linewidth = 1,
    color = "black",
    linetype = "dashed"
  ) +
  labs(
    x = "Residuals",
    y = "Density"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )

#ndist_plot_rpe+ndist_plot_rpe_no_logtransform
# QQ line
qqplot_rpe<-ggplot(SessionRPE_residuals, aes(sample = .resid)) +
  stat_qq(shape = 21, color = "black", fill = "gray80", size = 2) +
  stat_qq_line(color = "black", linetype = "dashed") +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )
qqplot_rpe_no_logtransform <-ggplot(SessionRPE_residuals_no_logtransform, aes(sample = .resid)) +
  stat_qq(shape = 21, color = "black", fill = "black", size = 2) +
  stat_qq_line(color = "black", linetype = "dashed") +
  labs(
    x = "Theoretical Quantiles",
    y = "Sample Quantiles"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )
# qqplot_rpe+qqplot_rpe_no_logtransform

##### Variance Influence Factor ### 
model_SessionRPE_3_lmer <- lmer(
  SessionRPE_lead1 ~ 
    Pride_gm_centered * PA_gm_centered + 
    Pride_gm_centered * Dynamics_centered + 
    Pride_gm_centered * Locus_centered + 
    Pride_gm_centered * Globality_centered + 
    Pride_gm_centered * Affiliation_centered + 
    Pride_gm_centered * Achievement_centered + 
    Pride_gm_centered * Power_centered + 
    (1 | ID),
  data = long_df,
  na.action = na.omit,
  REML = TRUE
)

vif_RPE_min<-vif(model_SessionRPE_3_lmer) %>% min() %>% round (2)

vif_RPE_max <- vif(model_SessionRPE_3_lmer) %>% max() %>% round (2)

###### Tests of normality ###############################################

#### Test for the Attribution Model #####
ntest_shapiro_rpe <-shapiro.test(SessionRPE_residuals $.resid)  
ntest_ks_rpe <-ks.test(SessionRPE_residuals  $.resid, "pnorm", mean(SessionRPE_residuals  $.resid), sd(SessionRPE_residuals  $.resid), exact = T)
ntest_ks_rpe_no_logtransform <-ks.test(SessionRPE_residuals_no_logtransform  $.resid, "pnorm", mean(SessionRPE_residuals_no_logtransform  $.resid), sd(SessionRPE_residuals_no_logtransform  $.resid), exact = T)


##### Testing for homoscedasticity (homogeneity of variance of residuals), and outliers in the residuals####

resid_plot_rpe<-ggplot(data = SessionRPE_residuals, aes(x = .fitted, y = .resid)) +
  geom_point(shape = 21, color = "black", fill = "gray80", size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = NULL
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )

resid_plot_rpe_no_logtransform<-ggplot(data = SessionRPE_residuals_no_logtransform, aes(x = .fitted, y = .resid)) +
  geom_point(shape = 15, color = "black", size = 2) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    x = "Fitted Values",
    y = "Residuals",
    title = NULL
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )
#resid_plot_rpe+resid_plot_rpe_no_logtransform
# Outliers (All)
ggplot(data = SessionRPE_residuals , aes(y= .resid)) + theme_gray() + geom_boxplot()

#Outliers per individual
outl_plot_rpe <- ggplot(SessionRPE_residuals, aes(x = .resid, y = ID)) +
  geom_boxplot(outlier.shape = 21, outlier.fill = "gray80", outlier.color = "black", outlier.size = 2) +
  labs(
    y = "Individual No.",
    x = "Residuals"
  ) +
  theme_classic(base_size = 12) +
  theme(
    axis.title = element_text(size = 12),
    axis.text = element_text(size = 10),
    panel.border = element_rect(fill = NA, color = "black")
  )


```

```{r exploring assumptions for the HLMs}
#| include: false


```

```{r values}
#| include: false

#### Creating a list with all commonly used descriptive statistics + other descriptive values ###############################################
descriptives_list <- mean_sd_median_min_max(df)
vars_not_normal<-which_var_not_normal(df)
vars_not_normal_with_p_values<-which_var_not_normal_p(df) %>% mutate(across(where(is.numeric), ~ ifelse(. < 0.001, "< .001", as.character(round(.,3)))))



#### Power analysis ####
pwr_result <- pwr.r.test(n = NULL,         
                     r = 0.5,           
                     sig.level = 0.05,  
                     power = 0.95,      
                     alternative = "greater") 

#

```

```{r tables}
#| include: false


#### correlation table ####
pride_variables<-c("Pride_base", "Hubris_base")
base_training_and_affect_variables<-df %>% ungroup() %>% select(ends_with("_base"), -matches("Pride_base|Hubris_base")) %>% names() 
motive_variables <- c("Achievement", "Affiliation", "Power", df %>% ungroup() %>% select(starts_with("Gen_")) %>% names())
attrib_variables <- c("Locus", "Dynamics", "Controlability_self")# 
correlation_variables<-c( pride_variables,base_training_and_affect_variables,motive_variables,attrib_variables)
corr_table<-df[,correlation_variables] %>% 
  generate_correlation_table2(c(
    "1. Pride", 
    "2. Hubris", 
    "3. Session Training Distance", 
    "4. Session Training Hours", 
    "5. Session Training RPE", 
    "6. Positive Affect", 
    "7. Negative Affect", 
    "8. Achievement", 
    "9. Affiliation", 
    "10. Power", 
    "11. Hope for Success", 
    "12. Fear of Failure", 
    "13. Hope for Belonging",
    "14. Fear of Rejection",
    "15. Hope for Control",
    "16. Fear of Loss of Control",
    "17. Locus",
    "18. Dynamics",
    "19. Controllability"
  ))

#### Skewness, Kurtosis and min-max range table###############################################

df_stat<-get_descriptive_table(df[, correlation_variables], language = "German")

df_stat$Variable <- c(
  "1. Pride", 
    "2. Hubris", 
    "3. Session Training Distance", 
    "4. Session Training Hours", 
    "5. Session Training RPE", 
    "6. Positive Affect", 
    "7. Negative Affect", 
    "8. Achievement", 
    "9. Affiliation", 
    "10. Power", 
    "11. Hope for Success", 
    "12. Fear of Failure", 
    "13. Hope for Belonging",
    "14. Fear of Rejection",
    "15. Hope for Control",
    "16. Fear of Loss of Control",
    "17. Locus",
    "18. Dynamics",
    "19. Controllability"
)

table_stat<-df_stat %>% flextable() %>% flextable::theme_apa() %>% autofit()
 

```

```{r graphs}
#| include: false


custom_labels <- c(
    "Pride_base" = "1. Pride", 
    "Hubris_base" = "2. Hubris", 
    "WeeklyKM_base" = "3. Weekly Training Distance (KM)", 
    "WeeklyH_base" = "4. Weekly Training Hours", 
    "WeeklyRPE_base" = "5. Weekly Training RPE", 
    "PA_base" = "6. Positive Affect", 
    "NA_base" = "7. Negative Affect", 
    "Achievement" = "8. Achievement", 
    "Affiliation" = "9. Affiliation", 
    "Power" = "10. Power", 
    "Gen_Success_hope" = "11. Hope for Success", 
    "Gen_Failure_fear" = "12. Fear of Failure", 
    "Gen_Belonging_hope" = "13. Hope for Belonging", 
    "Gen_Rejection_fear" = "14. Fear of Rejection", 
    "Gen_Control_hope" = "15. Hope for Control", 
    "Gen_LossControl_fear" = "16. Fear of Loss of Control", 
    "Locus" = "17. Locus", 
    "Dynamics" = "18. Dynamics", 
    "Controlability_self" = "19. Self-Controllability"
)

#print_all_histograms(df, bins_n = 30)
#print_all_histograms(df[correlation_variables])

 violin_plots<-print_all_violin_boxplots(df[correlation_variables], facet_ncol = 3, facet_nrow = NULL, custom_labels = custom_labels)


# long_df_filtered <- na.omit(long_df[, c(
#   "SessionKM_lead1", "Pride_gm_centered", "Dynamics_centered",
#   "PA_gm_centered", "Locus_centered", "Globality_centered",
#   "Affiliation_centered", "Achievement_centered", "Power_centered",
#   "Time", "ID"
# )])
# long_df_filtered$fitted_km <- fitted(model_SessionKM_3)
# long_df_filtered$fitted_km <- fitted(model_SessionKM_3)


# hlm_plot<-ggplot(long_df_filtered, aes(x = Time, y = fitted_km, group = ID, color = as.factor(ID))) +
#   geom_line(show.legend = F)+
#   geom_point(aes(x= Time, y= SessionKM_log), show.legend = F)+
#   labs(x = "Time", y = "Fitted Goal", title = "Predicted KM by ID") +
#   theme_minimal()+
#   labs(
#     x = "Session No. ",
#     y = "Running Distance",
#     color = "ID"
#   )

pride_dynamics_plot<- plot_model(
  model_SessionKM_4,
  type = "int",
  terms = c("Pride_gm_centered", "Dynamics_centered"),
  title = "Interaction: Pride Ã Dynamics"
)




globality_plot<-plot_model(model_SessionKM_4, type = "pred", terms = c("Globality_centered"), show.data = T, jitter = .2, grid = T, axis.title = c("Globality", "Running Distance in KM"), title = "Predicted running distance through Globality")# This shows more globality means less km, but its because of the negative interaction term with pride. 

# globality_plot<-plot_model(model_SessionKM, type = "pred", terms = c("Globality", "Pride"), show.data = T, jitter = .2, grid = T, axis.title = c("Globality", "Running Distance in KM"), title = "Predicted running distance through Globality") # Could refine with an interaction plot

# Diagnostic plots for model
Homoscedasticity_plotH <-plot_model(model_SessionKM_4, type = "diag") 


Homoscedasticity_plot <-plot_model(model_SessionKM_4, type = "resid") 

# Heatmap
p.mat <- cor_pmat(df[, correlation_variables])
str(df[, correlation_variables])
correlation_coefficients<-cor(df[, correlation_variables], use = "pairwise.complete.obs")

ggcorrplot(correlation_coefficients,
  p.mat = p.mat,
  type = NULL, insig = "blank", method= "circle", tl.srt = 90+
    scale_x_discrete(labels = custom_labels) +  # Apply custom labels to x-axis
  scale_y_discrete(labels = custom_labels)
)

heatmap<-ggcorrplot(correlation_coefficients, method= "circle", type =NULL,  tl.srt = 90,  p.mat = p.mat, insig = "blank")+
  scale_x_discrete(labels = custom_labels) +  # Apply custom labels to x-axis
  scale_y_discrete(labels = custom_labels)#https://www.youtube.com/watch?v=E3De2A73ako&t=1s
```

# Method

@kipchoge2020 @rstudio2024

## Analysis

We excluded participants manually if they reported data on less than two training sessions, if they did not participate in a structured training programme, or if they were neither runners nor triathletes. The baseline kilometer variable were standardized within their respective sport group, that is, running vs. triathlon. `r missings_percentage` of data were missings. Since most of the incomplete date was due to training sessions that were not completed, we decided against multiple imputation, following the reccomendations of \[Lit\]. Descriptive statistics were calculated for all variables - descriptive statistics - correlation

For the hierarchical linear models,the time-varying predictors pride and positive affect were group-mean centered, and the stable predictors attribution style (globality, dynamics, locus) and implicit motives (achievement, affiliation, power) were grand mean centered. This procedure entangles the between-person-effects from the within-person-effects. This is in line with recommendations of @Wang2015. They authors emphasize that a within-person effect can be present regardless of the between-person-effect, and vice versa. To illustrate this, it is possible that within a person, a lack of pride after a run predicts a greater running distance in the next session. At the same time, people who less proud on average do not necessarily run more.

The results for the hierarchical linear models are presented separately for each the dependent variables of this study: Session distance, session duration and rate of perceived exhaustion.
We used interaction terms of pride with positive affect, causal attribution and implicit motives to predict these dependent variables. The predictors were added to the null model in three steps: First, the interaction term of pride and positive affect, second, the interaction terms of pride and attribution styles, and third, interaction terms of pride and implicit motives. We then decided on the appropriate model based on fit indices and explanatory power, and then checked for three statistical assumptions: the absence of multicollinearity, homoscedasticity, and the normal distribution of residuals. We also assessed if a correlation matrix improved the model fit.

## Participants

The participants were `r descriptives_list$Age_mean` old on average (*SD* = `r descriptives_list$Age_sd`) ranging from `r descriptives_list$Age_min` to `r descriptives_list$Age_max` years

## Measures

## Procedure

# Results

Correlations are shown in @fig-corrplot.


## Session distance

In this model, we used interaction terms of pride with positive affect, causal attribution and implicit motives to predict running distance. The running distance was z-standardized to allow a comparison between the kilometer values reported by swimmers, runners, and triathlets. To allow  We added predictors to the null model in three steps: First, the interaction term of pride and positive affect, second, the interaction terms of pride and attribution styles, and third, interaction terms of pride and implicit motives. The result is shown in @tbl-hlmtable_km.

The residuals were normally distributed (*p* = `r round(ntest_ks_km $p.value, 2)` ). @fig-sessionkm_assumptions shows the deviation from the normal distribution along with the distribution of residuals. The latter should show no pattern, since this would indicate that there are predictors unaccounted for. While this seems to be the case, the residuals are slightly skewed to the left, indicating limited variance in the kilometer variable.

## Session duration

In this model, we used interaction terms of pride with positive affect, causal attribution and implicit motives to predict running distance. The running distance was z-standardized to allow a comparison between the kilometer values that triathletes reported, and those that were reported by runners. We added predictors to the null model in three steps: First, the interaction term of pride and positive affect, second, the interaction terms of pride and attribution styles, and third, interaction terms of pride and implicit motives. The result is shown in @tbl-hlmtable_h.

The residuals were normally distributed (*p* = `r round(ntest_ks_h $p.value, 2)` ). @fig-sessionh_assumptions shows the deviation from the normal distribution along with the distribution of residuals. The latter should show no pattern, since this would indicate that there are predictors unaccounted for. While this seems to be the case, the residuals are slightly skewed to the left, indicating limited variance in the kilometer variable.

## Session Rate of Perceived Exhaustion

 The regression coefficients are shown in @tbl-hlmtable_h. The third model with all predictors shows the lowest AIC and log likelihood. A more stable attribution style predicted a lower RPE, and so did the interaction terms of pride with positive affect, pride with a more external locus of control, pride with a higher implicit affiliation as well as a higher power motive. Only the interaction between pride and the implicit achievement motive predicted a higher rate of perceived exhaustion for each session.

The residuals were normally distributed in a Kolmogorov-Smirnov test (*p* = `r round(ntest_ks_rpe $p.value, 2)` ). This test is less sensitivie to small deviations from the norm [LIT]. @fig-sessionh_assumptions shows the deviation from the normal distribution in a QQ-Plot along with the distribution of residuals. The linear patterns that emerge in the residuals are a result of the discrete values in the session RPE data. 

To assess multicollinearity, we computed the variance influence factor which ranged from *vif~min~* = `r vif_RPE_min` to *vif~max~* = `r vif_RPE_max`. To account for the possible autocorrelation of repeated measurements, we employed an autoregressive process of order 1 (AR(1)) correlation structure using the corAR1 class from the nlme package in R. This structure was used to model the correlation between observations that are sequentially related in time. However, this did not result in a better model fit, so we used the model without the correlation structure (Model 3). 



::: landscape
```{r}
#| label: tbl-corrtable
#| tbl-cap: The Table Caption
#| apa-note: The note below the table.
corr_table

```

```{r}
#| label: tbl-hlmtable_km
#| tbl-cap: Hierarchical Linear Model Coefficients Predicting Running Distance
#| apa-note: Time varying predictors Pride and Positive Affect were cluster-mean-centered, fixed predictors were grand mean centered. In Model 4, the dependent variable was log-transformed to address heteroscedasticity and normality of residues. The fit indices of Model 4 are not directly comparable to models 1-3. 
hlmtable

```

```{r}
#| label: tbl-hlmtable_h
#| tbl-cap: Hierarchical Linear Model Coefficients Predicting Running Time
#| apa-note: Time varying predictors Pride and Positive Affect were cluster-mean-centered, fixed predictors were grand mean centered. In Model 4, the dependent variable was log-transformed to address heteroscedasticity and normality of residues. The fit indices of Model 4 are not directly comparable to models 1-3.  
hlmtable_h

```

```{r}
#| label: tbl-hlmtable_rpe
#| tbl-cap: Hierarchical Linear Model Coefficients Predicting Session Rate of Perceived Exhaustion 
#| apa-note: Time varying predictors Pride and Positive Affect were cluster-mean-centered, fixed predictors were grand mean centered. In Model 4, the dependent variable was log-transformed to address heteroscedasticity and normality of residues. The fit indices of Model 4 are not directly comparable to models 1-3. 
hlmtable_rpe
```
:::

```{r}
#| label: fig-corrplot
#| fig-cap: Heatmap
#| apa-note: This is the note below the figure.
#| fig-height: 10
#| fig-width: 10
heatmap
```

```{r}
#| label: fig-sessionkm_assumptions
#| fig-cap: Histogram and QQ-Plot of Residuals for the running Distance Model
#| apa-note: This is the note below the figure.
#| fig-height: 10
#| fig-width: 10
(qqplot_km + resid_plot_km)
  
```

```{r}
#| label: fig-sessionh_assumptions
#| fig-cap: Histogram of Residuals
#| apa-note: This is the note below the figure.
#| fig-height: 10
#| fig-width: 10
(qqplot_h + resid_plot_h)
  
```

```{r}
#| label: fig-sessionrpe_assumptions
#| fig-cap: Histogram of Residuals
#| apa-note: This is the note below the figure.
#| fig-height: 10
#| fig-width: 10
(qqplot_rpe + resid_plot_rpe)
  
```

```{r}
#| label: fig-violin
#| fig-cap: Violin Plot with boxplots
#| apa-note: This is the note below the figure.
#| fig-height: 15
#| fig-width: 10
violin_plots
```

```{r}
#| label: fig-globality_times_pride
#| fig-cap: Predictive Contribution of Globality, which interacts with pride
#| apa-note: This is the note below the figure.
#| fig-height: 15
#| fig-width: 10
globality_plot
```

# Discussion

The variance influence factors suggest low multicollinearity [for a discussion see @Obrien2007], which is also evident from the correlation table. 

## Limitations and Future Directions

## Conclusion

# References

<!-- References will auto-populate in the refs div below -->

::: {#refs}
:::

# Appendix

# Title for Appendix
